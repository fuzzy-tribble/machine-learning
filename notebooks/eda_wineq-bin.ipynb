{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA: Wine Quality Prediction (binary classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo\n",
    "from sklearn.decomposition import FastICA\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from helpers.base_imports import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create new EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eda = EDA(name=\"wineq\")\n",
    "eda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get raw dataset from remote source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch dataset\n",
    "data = fetch_ucirepo(id=186)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.data.features\n",
    "y = data.data.targets\n",
    "\n",
    "df = pd.concat([X, y], axis=1)\n",
    "disp_df(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!!!!! STOPPED HERE...need to make quality rating a binary choice (try to chose a split/threshold that roughly evenly splits the data???!?!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eda.update_param(\n",
    "    \"description\", \"Predict the quality of wine based on physicochemical tests\"\n",
    ")\n",
    "eda.update_param(\"n features\", X.shape[1])\n",
    "eda.update_param(\"n samples\", X.shape[0])\n",
    "eda.update_param(\"f/n ratio\", X.shape[1] / X.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eda.summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for missing values\n",
    "X.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eda.update_param(\"noise\", \"None, no missing vals\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Calculate skewness for numeric columns only\n",
    "# numeric_X = X.select_dtypes(include=[np.number])\n",
    "# skewness = numeric_X.skew()\n",
    "\n",
    "skewness = X.skew()\n",
    "summary_stats = X.describe().T[[\"min\", \"max\", \"mean\", \"std\"]]\n",
    "summary_stats[\"skewness\"] = skewness\n",
    "summary_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_feature_statistics(X, X.columns, line=False)\n",
    "fig.savefig(f\"{FIGS_DIR}/{eda.name}_feature-statistics.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eda.update_param(\"skewness\", \"lots of skweness in the data\")\n",
    "eda.update_param(\"stats\", \"strangeness\")\n",
    "eda.update_param(\"outliers\", \"many outliers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class distribution of whole dataset\n",
    "ax = sns.countplot(x=y.iloc[:, 0])\n",
    "plt.title(f\"Target Class Distribution ({eda.name})\")\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Count\")\n",
    "\n",
    "# Annotate each bar with the count\n",
    "for p in ax.patches:\n",
    "    height = p.get_height()\n",
    "    ax.annotate(\n",
    "        f\"{height}\",\n",
    "        (p.get_x() + p.get_width() / 2.0, height),\n",
    "        ha=\"center\",\n",
    "        va=\"center\",\n",
    "        xytext=(0, 5),\n",
    "        textcoords=\"offset points\",\n",
    "    )\n",
    "\n",
    "plt.savefig(f\"{FIGS_DIR}/{eda.name}_target-class-distribution.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eda.update_param(\"class balance\", \"~Normal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data=df, hue=\"quality\", palette=\"bright\")\n",
    "plt.savefig(f\"{FIGS_DIR}/{eda.name}_pairplot.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a heatmap of the correlation matrix\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(X.corr(), annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
    "plt.title(f\"Correlation Matrix ({eda.name})\")\n",
    "plt.savefig(f\"{FIGS_DIR}/{eda.name}_correlation-matrix.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eda.update_param(\"correlations\", \"several moderate/low correlations, 1-2 higher\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality Reduction Potential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA - number of components to explain 95% variance\n",
    "pca_pipe = Pipeline(\n",
    "    [\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"pca\", PCA()),\n",
    "    ]\n",
    ")\n",
    "pca_pipe.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explained_variance_ratio = pca_pipe.named_steps[\"pca\"].explained_variance_ratio_\n",
    "cumulative_explained_variance = np.cumsum(explained_variance_ratio)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(cumulative_explained_variance, marker=\"o\", linestyle=\"--\")\n",
    "plt.xlabel(\"Number of Principal Components\")\n",
    "plt.ylabel(\"Cumulative Explained Variance\")\n",
    "plt.title(\"PCA - Cumulative Explained Variance\")\n",
    "plt.axhline(y=0.95, color=\"r\", linestyle=\"--\")  # Threshold for 95% explained variance\n",
    "plt.show()\n",
    "\n",
    "# Number of components to explain 95% variance\n",
    "num_components_95 = np.argmax(cumulative_explained_variance >= 0.95) + 1\n",
    "print(f\"Number of original features: {X.shape[1]}\")\n",
    "print(f\"Number of components to explain 95% of the variance: {num_components_95}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ICA - number of independent components\n",
    "ica_pipe = Pipeline(\n",
    "    [\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"ica\", FastICA()),\n",
    "    ]\n",
    ")\n",
    "components = ica_pipe.fit_transform(X)\n",
    "\n",
    "# Number of independent components\n",
    "num_independent_components = components.shape[1]\n",
    "print(f\"Number of original features: {X.shape[1]}\")\n",
    "print(f\"Number of independent components found: {num_independent_components}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eda.update_param(\n",
    "    \"DR potential\",\n",
    "    \"PCA: 9 components to explain 95% variance, ICA: 11 independent components\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save EDA results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eda.summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eda.save(overwrite_existing=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create and save a shuffled 80/20 train/test split"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
